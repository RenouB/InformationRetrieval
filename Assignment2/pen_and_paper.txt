Task 2

1. What information does the task description contain that the master gives to a parser?

Master must tell the parser what subset of the corpus to parse and how it must portion the index it creates.


2. What information does the parser report back to master upon completion of the task?

The parser communicates that it has completed its task, and reports back the references to each portion of the index it has created.


3. What information does the task description contain that the master gives to an inverter?

The master communicates to the indexer the locations of each of the subindexes for which it must create an inverted index and postings list.


4. What informatino does the inverter report back to the master upon completion of the ask?

The inverter will return the reference to the inverted index and postings list it has created.



Task 3

When indexes get very large, it becomes difficult to store them in memory, and we must move then to disk. For dynamic collections this is particularly problematic. Each time we wish to update our index with new terms or postings, we must recalculate it entirely while merging the new elements. This will occur very often, incurring high costs and greatly reducing the user experience during the merge. Logarithmic merging is one technique used to mitigate these problems.

Logarithmic merging functions roughly as follows:

We have an index, m0, of size n that is stored in memory. We also have indexes that are stored on disk in bins, which are organized according to increasing size.  The size of each bin is n*(2^k) where k is the position of the bin in the line of bins, starting from zero. We thus have bins b0, b1, b2 ... bx. Notice that the size of the bins increases logarithmically. PLEASE EDIT THIIIIIS TO MAKE THE  NUMBERS PRETTY SUBSCRIPTS

When m0 is populated up to size n, we begin merging it to b0. To do this it is initialy stored in a temporary location m1. m1 is merged to b0, and b0 is thus filled with the former contents of m0. As m0 is once again filled to n, the contents are once again stored in m1 in order to prepare a merge to disk. However, we cannot merge to b0, because it has already been completely filled. We will instead merge m1 and b0, restructuring their contents into b1. m0 and b0 are now again empty and prepared to accept new elements. This process continues, continually creating bins of greater size in order to accomodate new terms. When b0 and b1 are full, their contents are merged and restructured into b2, and so on.

As a result of this logarithmic merging process, we will have many small merge operations and relatively few large merge operations as we update our indexes. Logarithmic merging is much more efficient.

However this technique does have certain disadvantages. We no longer have one index, but many seperate indexes. This results in a slower query process. Likewise, we run into complications should we wish to remove terms or postings (although one can quickly compensate for this by passing query results through a filter).


WE can use a distribited compute cluster like map reduce in combination with logarithmic merging by

Solve for k & b

b~ 0.5
k = 30
30,000 = k(1,000,000)^0.5

b ~0.49
k = 37

GIGA word count = 948,683 950,000

detailed work

b ~0.501
k~30.353

GIGA word count = 980,000 spc. 979,945

nearly perfect

k = 21.863
b = 0.5229

GIGA word count = 1,111,245 terms

5.
217
Binary = 1101 1001
VB = 0000 0001 1101 1001

Gamma
offset = 101 1001
length = 11111110
Gamma code = 11111110, 1011001

6. 11110100001111101010111000

11110,1000 0 111110,10101 110,00

1 1000 = 24
0 = 1
11 0101 =53
100 = 4
[24, 1, 53, 4] 


K-Gram index
pro
more space efficient
can solve multiple intersections 
can return likelihood of search query (can control the accuracy)
Con
False positives many
slower
requires post-processing
two inverted indexes (one of bi-grams with terms containing those bi-grams, and reg Inverted index)

Permuterm index
pro 
faster
no post-processing
much less false positives

con
blows up the size of dictionary 
only returns exact matches
cannot process multiple intersections
